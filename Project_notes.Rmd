---
title: "Notes on project"
output:
  word_document: default
  html_notebook: default
editor_options:
  chunk_output_type: inline
---

Data for project

<https://drive.google.com/drive/folders/1OR9heTa36xuv2Y9GAFMycd8LN5Oavh9A?usp=sharing>

10/14/2023

Add lat and log to the bat2021_v2 database.

Then, the predictors matrix for the population analysis section is calculated.

------------------------------------------------------------------------

10/15/2023

I tried copying the lat and log, but there seems to be a problem, as points are not plotting correctly. There might be problems with the coordinates. Update: I tried again, and the elevator package loaded and worked. However, I didn't display any elevation.\
I tried the package raster, plotted the DEM for Idaho, and obtained elevation for each site.

\
For the population analysis, I want to include the moon's phase, illumination, elevation, and riparian vegetation.

I will calculate the riparian vegetation with the NDVI. Unfortunately, it is not working as it should. I am using·  code in the cleanup script. ChatGPT helped me generate it, but it is still not working well.

11/17/2023

Per the recommendation of Jen, I created the matrix lano_js that should be used to run the model in the script pop_model. We will be using just a single species data set for testing. To the file lano_js, we removed last week and the site column. We also made 0 data because we didn't want.

I just noticed that when I write a file with the write.csv function there's a there's a new index column created that has a number for each row. How to prevent this?

write.csv(iris, file = "iris.csv", row.names = FALSE)

you have to set the row.names=false argument.

11/20/2023\
I ran the data work but got an error anyway.

```{r}
# urn-in + Update 1 (30000)Error in checkForRemoteErrors(val) :
# 
#   5 nodes produced errors; first error:
# 
# Error parsing model file:
# 
# syntax error on line 44 near "}"
```

I think there's something wrong with the model when we feed it to JAGS.

we fixed this.

11/29/2023

I talked to Jen Cruz, and she mentioned I have to be careful with the things that I include in the GitHub. For example, I should not trace the R project where I am working. I should just use trace the changes in the scripts. According to her tracing the project could break cause trouble in the future.  

------------------------------------------------------------------------

12/4/2023

-   I worked on the bat_pop_analysis.R script. I have organized the Lano, slc, and obs. cov, so they have no site column, and they are arranged in ascending order of week.

-   I created this R mark notebook to take notes of the thing here instead of a Word document.

-   Created obs.cov2 for moon. illumination

------------------------------------------------------------------------

12/05/2023

-   started building the plotting code. got a margina plot for elevation but not for light or dark.

-   need to calculate weather variables.

-   need to calculate NDVI

-   I meet with Jen she mentioned that the models did not converged so I increase the max number of iterations to one million. the results still not converged...

------------------------------------------------------------------------

12/06/2023

-   I need to build the weather data base to run the pop models.
-   Problems with the model :\
    ![m1 diag plot](figures/m1_diag_plot.png){width="957"}

-There are several peaks for density plot. This means there's problems with identifiability because there are multiple plots in the posterior?\
-the chains are not in the same space. This means they are getting stuck in the same spot right?

When I increased to two million the Rhat values decreased? does this mean we are approaching convergence?

------------------------------------------------------------------------

12/19/2023

meeting with Jen:

-   The model is still not converging. We change the random intercept for abundance from site to week. It seems there is great variability in bat activity between weeks (see lano_js.csv). One solution might be to select certain weeks to be the ones that we analyze. Another solution is to add an extra level to the model to account for availability.

------------------------------------------------------------------------

12/21/2023

-   I ran into a problem with the data from 2021 for bats. The raw data produced with the script build data base v3 and v4. Currently the 2021 data has only 13 sites. It should be 14 because one site is missing entirely from the data base. I intended to update the data base with new code to get all the data points. Unfortunately it seems I am not collecting all the output files from Sonobat (Data_CumulativeSonoBatch_v420). I am in the process of compiling them but making a list of all the txt files using the function list.files() take a long time. So I am using the function dir_ls() from the fs package.

------------------------------------------------------------------------

01/23/2023

In the code build_data_base_v4 I was able to see what what happening with the bat 2021 data. - some files have not been analyzed with sonobat and are missing from the database - once all the .txt files in the 2021 folder are compiled, there are two ways of getting the data out.\
- sonofiles1\<- sm3dirs[grepl("\_CumulativeSonoBatch_v420.txt", sm3dirs)] - sonofiles2\<- sm3dirs[grepl("SonoBatch_v420.txt", sm3dirs)] \# this one doubles the data as it also get all the cumulativesonobatch files. I will be using the first one.

-   Also, we need to start using the column marked as 1st for species present in the recordings. This provides us with more data to work with compared to just the SpAccp column.

------------------------------------------------------------------------

1/25/2024

I am still running Sonobat on some 2021 data and it needs to be run in all 2023 part b data.

I will start building the 2022 database for bats.

-   I need to check what days were for each site. I need to check what dates where sampled for insects with bucket traps.

-   I need to check the variation of bat calls per species by week

------------------------------------------------------------------------

1/29/2023

-   I created bat2022_v2. It has the species and the dates. we need to calculate the moon.

-   I also realized that I should calculate the date for the raw data. That way, I could know how many hours each recording was working.

-   **IMPORTANT**: the batraw2022 database has data for iron 1 to 6. We need to fix this one too.

    ------------------------------------------------------------------------

1/30/2023

-   I will fix the issue with the batraw2022 data, so we have the data for all the sites. One possible issue is that we need to run more sites with Sonobat.

-   I also realize I need to check some call data data to corroborate these are properly ID correctly.

-   I can run some Sonobat data through kaleidoscope to see how these compare.

------------------------------------------------------------------------

1/31/2024

-   I updated the code for the 2021 data but and I believe not all audio files have been ran trough Sonobat.

    ------------------------------------------------------------------------

02/13/2024

After these two weeks I realized that for 2021 we have two sites failed (long02, and Viz4).\
It also seems like the old table fro 2021 data had lots more data and I don't know why. It might be possible that we merged tables we didn't wanted.

Next step check the updated table and ask. How many files there are and how many nights of data we have for each site. It could be possible not all sm3 were on at all time.\

------------------------------------------------------------------------

Ok I think the Sonobat files made with v420 and v4.4.5 once they are merged the columns might not align and might mes up the merging of files and thus creating a full data file.

solution: proceed as for now and continue running all the files through sonobat to run them all using just sonobat v4.4.5

I am working with the cleanup_script_v2 to be able to check the data and see what sites have data and how many data points we have. I will also include the from two columns the sppaccp and the \~spp. this way we will increase the data we have.\

------------------------------------------------------------------------

2/21/2024

I am trying to update the files for bat2021 data base. I am missing data for viz03. the build_database script is not building the database properly and skips files even there are a Sonobat files for that site.\
I am trying to fix that so I can start working with Jen again.

Ok, I updated the database for 2021 and created bats2021_v5.csv in the pioneerlights project. I updated the cleanup_script_v2 and now has the lates data file. I will be working on this next.

I merged the data from cols Accpspp and \~spp into the column Spp.plus. We need to see how this compares now.

```         
table(bat2021_v2$site,bat2021_v2$SppAccp) #how many rows pe
```

the previos code helps visualice this

creating the new Sp.plus col adds more data to 2021\
table(is.na(bat2021_v2\$Sp.plus)) FALSE TRUE 180555 189779 \> table(is.na(bat2021_v2\$SppAccp)) FALSE TRUE 112713 257621

------------------------------------------------------------------------

02/26/2024

I am trying to work with the 2021 data set. There are some issues with the data apparently there are some rows that did not work well. I need to figure out what is going on.\
table(is.na(bat2021_v2\$date_time))

FALSE TRUE

370334 69

there are 69 instances where the data was not able to parse. I think this is a problem because of the output Sonobat give us.

Ok now I am exploring the data set to see if we can get more data from the columns X1st and Xspp. It seems like XSpp has too many conbinations. In contrast, X1st is not entirely sure to work because we are not "confident" the calls identify there are the actual calls.\
I am not sure the matrix are build properly for when I tally calls by week. I believe there might be an error when counting NAs.

------------------------------------------------------------------------

2/28/2024

I crated a new bat species observations by week file for Myly. I think there's still a lot of variability between weeks on the number of calls. there's one week where the calls go from 17 to 1261. That might be too much variability for the model to handle.

------------------------------------------------------------------------

Change approach. We are not using Sonobat, we are using Kaleidoscope. There is definitively differences in the number bat calls found and the species ID. I am trying to build a visualization of the weeks and dates that each recording was working.

we need a matrix of days species and the days thing were working for each species.

| site/species 1 | week1 | week 2 |
|----------------|-------|--------|
| 1              | 1     | 1      |
|                |       |        |
|                |       |        |

Maybe one by julian day by each species.

| site/species1 | jday1 | jday2 | jda3 | jd4 | jda5 | jda6 |
|---------------|-------|-------|------|-----|------|------|
| iron1         | 1     | 1     | 1    | 1   |      |      |
|               |       |       |      |     |      |      |
|               |       |       |      |     |      |      |

------------------------------------------------------------------------

7/1/2024

I worked on the alpha and beta diversity. I am struggling finding calculate the beta diversity.\
next:\
put together the whole data for the three season.

------------------------------------------------------------------------

7/2/2024

I ran a beta diversity with the vegan package and there is no difference in species composition between lit sites and drainages.

I put together a table for robomoth 2022

next: Robomoth 2023 and start exploring other ways to show no differences in beta diversity.

------------------------------------------------------------------------

07/03/2024

Did some code o calculate the beta diversity and plotted the dissimilarity between sites. I also did a simple plot for alpha diversity.

------------------------------------------------------------------------

07/08/2024

worked on the BAT package to calculate beta diversity.

------------------------------------------------------------------------

07/11/2024

I tried to fixed the weather data and the effort data to add an offset to the model an maybe improve how it works.

------------------------------------------------------------------------

07/16/2023

Weather updated

next step try an offset model

0724/2024

I have been working on plotting the random effects and the partial predictor plots for the model manually and using sjplot.\
The next step should be rerun the model with the data from 2022 and 2023. I am building those databases right now and should load soon.

------------------------------------------------------------------------

8/07/2024

-   I coded the year variable in the bm data set a as -1,0,1 for 2021,22,23 respectively

-   change the scaling on the model from 2sd to just by one standard deviation

-   remove ndvi and max-freq from the model m1.5nb. I also filtered out the "no-Id" calls from the model before running it.

-   I need to code the treatment as -1, 0, 1 for sites close to lit sites and control sites. I needto check the time and date inthe raw data. when parsing these from the robomoth they did not work well but it could be due to the recordings comming from audiomoths.

------------------------------------------------------------------------

08/14/2024

-   from the m1.5nb model, I should plot the marginal effects for the variables that are not in the random effects but have an significan effect. For exampl (elevation, tem, wind, year)

-   I plotted yr

![](images/clipboard-1745413645.png)

------------------------------------------------------------------------

8/16/2024

I learned to use the line equation to predict the values for building the marginal predictors plot and the random effect plots. for [[example:\\\\](example:){.uri}](%5Bexample:%5D(example:)%7B.uri%7D){.uri}

fday\<-confint(m1.5nb)

predabund \<- exp(t(fday[c(1,3,4),]) %\*% t(cbind(int, jday.s, jday.sqr)))

Here we are using the intecept and slope matrix to multiply it by obseved values and get the predicted values.

Below we are doing something similar but for the randome effects where we are addign the fixed coefficients to the random effects coefficients (rss) then we are pedicting the response based on observed values and the coeficients that we have so we can create a plot.

``` r
 rss <- ran.efs

rss[, 1] <- rss[, 1] + fix.efs[1]  #adding fixed effects to each of the random effects
rss[, 2] <- rss[, 2] + fix.efs[2]
rss[, 3] <- rss[, 3] + fix.efs[3]
rss[, 4] <- rss[, 4] + fix.efs[4]

#create id column
#view
rss
a<-rss[,1:3]
b<-t( cbind( ones, jday.s, jday.sqr))
indpred<- exp( as.matrix(a) %*% as.matrix(b) )

abunddf <- data.frame(t(indpred), jday.s, ord.day)
```

------------------------------------------------------------------------

08/19/2024

tried the random effets plot for the sp.\
I got stuck... it is not working very well.

------------------------------------------------------------------------

08/22/2024

I got a hard setback when Jen told me I need to rethink how I am plotting the marginal effects plots. I feel a little discouraged but I think I agree with Jen and need to improve my understanding.

today I plotted most of the fixed effects that are not included in the random slopes.\
I also did a step by step guide to plot those confidence intervals.

![wind marginal effect example](figures/glmm_v1/wnd_feff_v1.png)

------------------------------------------------------------------------

8/26/2024

I was able to plot the graph for the treatment effect on the bat sp. I think I got all the rando effect plots and marginal effects plots.\
![treatment effect on bat calls.](figures/glmm_v1/trmt_raneff_v1.png)

------------------------------------------------------------------------

09/03/2024

I calculated the distance to the nearest two lit sites from each point. Then I ran a model with that distance as explanatory variable. The results were not that much different from the one coding light as present or absent.

``` r
 summary(m1.7nb)
 Family: nbinom2  ( log )
Formula:          n ~ Sum_Distance_s + jday_s + I(jday_s^2) + percent_s + l.illum_s +      avg_wind_speed_s + avg_temperature_s + yr_s + elev_mean_s +      moo + (1 | site) + (1 + trmt_bin + jday_s + I(jday_s^2) |  
    sp)
Data: bm2

     AIC      BIC   logLik deviance df.resid 
125032.8 125211.8 -62493.4 124986.8    17748 

Random effects:

Conditional model:
 Groups Name        Variance Std.Dev. Corr              
 site   (Intercept) 0.06293  0.2509                     
 sp     (Intercept) 2.41084  1.5527                     
        trmt_bin    0.10191  0.3192    0.79             
        jday_s      0.01170  0.1082    0.23 -0.05       
        I(jday_s^2) 0.02035  0.1427   -0.79 -0.77  0.24 
Number of obs: 17771, groups:  site, 15; sp, 14

Dispersion parameter for nbinom2 family (): 1.25 

Conditional model:
                   Estimate Std. Error z value Pr(>|z|)    
(Intercept)        1.868218   0.335804   5.563 2.65e-08 ***
Sum_Distance_s    -0.036203   0.101152  -0.358  0.72041    
jday_s             0.060505   0.032390   1.868  0.06176 .  
I(jday_s^2)       -0.072637   0.034281  -2.119  0.03410 *  
percent_s          0.029202   0.076454   0.382  0.70250    
l.illum_s          0.024233   0.007687   3.153  0.00162 ** 
avg_wind_speed_s   0.059415   0.007880   7.540 4.71e-14 ***
avg_temperature_s  0.041596   0.009418   4.417 1.00e-05 ***
yr_s              -0.072594   0.009920  -7.318 2.52e-13 ***
elev_mean_s        0.158565   0.083192   1.906  0.05665 .  
moo               -0.008597   0.093947  -0.092  0.92708    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

------------------------------------------------------------------------

09/10/2024

updated the diversity script and saved some graphs.\
I need help interpreting the beta diversity graph.

![](images/clipboard-775704578.png)

there's not a clear pattern of species diference

next: do a bipartite analysis.

------------------------------------------------------------------------

9/23/2024

I updated the bm.miller.day. csv file. This file calculates properly the activity index according to miller. I was forgetting to not double count calls that occurred in the same minute. Maybe I could try 5 minutes ai index to see if that makes a change in the patterns observed.

next is to run the same models with the ai index as I did for the whole data.

------------------------------------------------------------------------

11/19/2024

I sitill need to run all the data with the bm.miller.day.csv.

-   need to recalculate values with the moonlit package for moon illumination

-   need to correct for abundance.

    I will do this by getting all the detentions by at lit and dark and getting the difference between both. then modeling such difference.

-   find some temporal change look one note notes [Jesse meeting](onenote:https://d.docs.live.net/389838b7e3cff5ec/Documentos/phd/Phd_meetings%20advisors.one#Jesse%20meeting&section-id=%7BD72C4F66-1EBB-43B2-9B02-FF45D4030D0F%7D&page-id=%7B646664F3-8A08-4FBC-8106-B794329320F6%7D&end)  ([Web view](https://onedrive.live.com/view.aspx?resid=389838B7E3CFF5EC%2130314&id=documents&wd=target%28Phd_meetings%20advisors.one%7CD72C4F66-1EBB-43B2-9B02-FF45D4030D0F%2FJesse%20meeting%7C646664F3-8A08-4FBC-8106-B794329320F6%2F%29))

-   

did:

I worked on the correction for the bat calls. Not sure I got it right. it seems off and there's no way to model the difference because there's no way to assign it to a site...

\

------------------------------------------------------------------------

11/21/2024

Trying to calculate the moon predictor using the [moonlit](https://github.com/msmielak/moonlit) package. Not working very well to calculate because the data time I have are stored as UTC and when I pass it to MDT the night turns into day and the moon calculations don't work.

-   if I just give the function dates it calculates everything for the day and there's no moon.

------------------------------------------------------------------------

11/22/2024

I worked on the code to see if it would be bettert to create a sequence of dates and times to calculate the moon illumination. It kind of worked but the file is too large. I was looking at the cheatsheet form lubridate and I might need to try force_tz or with_tz() and try again with the date and times of the actual data collected.

------------------------------------------------------------------------

I am still trying to calculate the moon illumination, however I have found a couple things to fix.

-   First I realized that I had to use the force_tz() function to make the date-time column into "America\\denver" time zone without changing the actual time. If this is not done, the times are all wrong for when you calculate the moon illumination.

-   second: I realized that when merging dates and times that are ymd-00:00:00 that corresponds to midnight the information about midnight disapeared. the time was parsed out of the column. see code prep_for_glm.R

Doing: I am figuring out how to prevent midnight times to disappear when merged with a date and parse it as time.\
I did some work and tried my best to make it work. The moon.intensity function eventually worked. I can't make the moon stats function to work.

------------------------------------------------------------------------

12/5/2024

I did my best to make the moonstat function work. However, I needed more help, so I asked Kyle Shannon. He will help me run the data.

------------------------------------------------------------------------

12/09/2023

the moon intensity calculated with moonlit worked after some modification from Kyle Shannon. The problem is the moon stat function. It didn't work because the process takes too long to run. I am going to run a small sample of with moonlit and suncalc to see if the timings are the same and then just take in consideration the suncalc one.

------------------------------------------------------------------------

12/12/2024

script: prep_for_glmm

To ensure accuracy in analyzing date-time data, all entries corresponding to midnight (**`00:00:00`**) in the **`datetime`** column are identified and incremented by 10 seconds. This was achieved by:

1.  Parsing the **`datetime`** column as **`POSIXct`** with the "America/Denver" time zone using **`ymd_hms`**.

2.  Filtering midnight entries using **`format(datetime, "%H:%M:%S") == "00:00:00"`**.

3.  Adding 10 seconds selectively to these rows using **`if_else`** and **`+ seconds(10)`**.

This adjustment prevents potential misinterpretation of exact midnight timestamps in downstream analyses.

-   I created the normalized_bm.csv data set to control for abundance. According to Jesse, this helps us see if there is a difference in the number of bats at lit and dark sites over time.

------------------------------------------------------------------------

Carlos 12/13/2024

I started working on analyzing the normalized data to see if it changes by time in the glmm_norm.R script.\

-   I encountered a problem while calculating the correlation between numeric variables. I realized the normalized data should have a special case when a species has no activity in the control site but it is present in the experimental site. If left as it is the result is NA as we are dividing the experiment/ control sites.

------------------------------------------------------------------------

![](images/clipboard-3251885484.png)

-   From the figure above, it seems that the data is zero-inflated and we need to account for that when analyzing it. (graph fro pep_for_glmm.R script)

-   I corrected the data for the cases when the control where 0 and now we can check it

Bad news I ran a few models with the data I have, the models are not a good fit because of residuals plots showing a pattern.

-   I tried one solution: I made the normalized abundance bound between zero and one. I end up doing a change in the normalization calculation\

    `normalized_activity = experimental_activity / (control_mean+ experimental_activity)  # Calculate normalized activity`

    `)`

This way we don't have trouble with the zeros and stays between zero and 1.

-   I will try to find a model that works with this one.

------------------------------------------------------------------------

I was able to run run a couple models by calculating a new variable: bin_act.\
\
**Binary Indicator**: Create `bin_act`:

-   `1` if experimental activity ≥ control mean.

-   `0` otherwise.

This allow me to run a couple of models a glm and a glmm. both seemed ok althoug I don't know how to evaluate the fit yet.

------------------------------------------------------------------------

12/18/2024

I ran a model with the bin_act variable, and it seems that we don't see any difference between activity and years, but the model only explains 11 percent of the variance.

year + jday +jday2 seemed to be significant, but the model appears to be bad...

Ideas:

-   focus on finding the moon and weather variables that are more relevant.

-   work on the data for bats to finish the analysis.

-   se if there is a difference in activity curves between lit and dark sites.

-   focus on the buzz counts

-   focus on bird data

------------------------------------------------------------------------

1/07/2025

trying to get plot the jday and year random effects plots.

------------------------------------------------------------------------

1/08/2025

I tried creating a random effect plot for the time variables day and season, but these were not working. The matrix multiplication fails when I am predicting values from the model parameters. I don't know how to move from that.

Lines2 78-318 in the glmm_norm_v1.R script

------------------------------------------------------------------------

1/17/2025

I have the variable j_diff. That is the difference Jesse recommends to calculate. Now I tried to model it but my model is singular... I need to fix it.

------------------------------------------------------------------------

1/21/2025

I had a meeting with Jen for discussing the normalization. I realized I had some issues with the models. More importantly she recomended that I run an interaction effect.\
\
I created the rowlarge col for the files that need to be vetted in with kaleidoscope. for bats that have too many calls at certain sites.

to do:

Make sure you standardize by two standard deviations given I have different predictors.

-   I ran the model m1.9nb but I am not sure it is working. \
    I need to asses the DHARMa residuals plot and see what does the ks test tell you.
